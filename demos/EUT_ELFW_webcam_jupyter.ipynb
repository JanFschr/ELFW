{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faces in the Wild with GCN Semantic Segmentation\n",
    "This code snippet runs the gcn semantic segmentation network over the webcam.\n",
    "\n",
    "Play with:\n",
    "\n",
    "1. A hat, a cap, or any wearable on top of your head.\n",
    "2. Take some sunglasses on.\n",
    "3. Try with moustache or beard.\n",
    "4. Put a mouth-mask on (or simulate it with a napkin).\n",
    "\n",
    "*Eurecat 2019 - Rafael Redondo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream stopped\n"
     ]
    }
   ],
   "source": [
    "# Make sure your network has been trained with this architectural parameters\n",
    "target_size = 256\n",
    "num_classes = 7\n",
    "num_levels = 3\n",
    "\n",
    "# Download from https://eurecatcloud.sharepoint.com/:u:/r/sites/audiovisualteam/Shared%20Documents/ELOF/FacesInTheWild/Checkpoints/gcn-dataset_3-levels_3-lr_0.0001-lrdecay_0.1-lrpatience_10-wdecay_0.0005-momentum_0.99-dataaugmen/gcn-epoch_0480.pth?csf=1&e=vjEPyY\n",
    "checkpoint = \"./data/gcn-epoch_0480.pth\"\n",
    "\n",
    "# Colorize your labeled classes\n",
    "label_colors = [\n",
    "    (0, 0, 0),\n",
    "    (0, 255, 0),\n",
    "    (0, 0, 255),\n",
    "    (255, 255, 0),\n",
    "    (255, 0, 0),\n",
    "    (255, 0, 255),\n",
    "    (0, 255, 255)]\n",
    "\n",
    "# Model loading (Resnet may take a while to download)\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.insert(1,'../pytorch-segmentation')\n",
    "from gcnX import FCN\n",
    "\n",
    "model = torch.nn.DataParallel(FCN(num_classes, num_levels))\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "model.cuda()\n",
    "model.eval()\n",
    ";\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from io import BytesIO as StringIO\n",
    "from IPython import display\n",
    "\n",
    "def showFrame(a, fmt='jpeg'):\n",
    "    f = StringIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    display.display(display.Image(data=f.getvalue()))\n",
    "    \n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if not vc.isOpened():\n",
    " \n",
    "    print(\"Error opening webcam\")\n",
    "    \n",
    "else:\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "                capturing, image = vc.read()\n",
    "                \n",
    "                if not capturing:\n",
    "                    break\n",
    "                    \n",
    "                offset = int((image.shape[1] - image.shape[0]) * 0.5)\n",
    "                image = image[:, offset:offset + image.shape[0]]\n",
    "                image = np.flip(image,1)\n",
    "                image = Image.fromarray(np.uint8(image))\n",
    "                image = image.resize((target_size, target_size), Image.BILINEAR)\n",
    "\n",
    "                # Pass forward\n",
    "                img = ToTensor()(image)\n",
    "                img = Normalize([.485, .456, .406], [.229, .224, .225])(img)\n",
    "                img = Variable(img).cuda().unsqueeze(0)\n",
    "                scores = model(img)  # first image in batch\n",
    "                label_probs = F.log_softmax(scores[0], dim=0).cpu().detach().numpy()\n",
    "\n",
    "                # Composite\n",
    "                segments = np.zeros((target_size, target_size, 3))\n",
    "                labels = np.argmax(label_probs, axis=0)\n",
    "                composite = np.array(image)\n",
    "                for l in range(len(label_probs)):\n",
    "                    indexes = labels == l\n",
    "                    for c in range(3):\n",
    "                        segments[:, :, c][indexes] = label_colors[l][c]               \n",
    "                        #composite[:,:,c][indexes] = (1-label_probs[l][indexes]) * composite[:,:,c][indexes] + \\\n",
    "                         #                           (a * composite[:,:,c][indexes] + (1-a) * label_colors[l][c]) * label_probs[l][indexes]\n",
    "                \n",
    "\n",
    "                a = 0.6     # the smaller the more intense the blending is (more greenish)\n",
    "                image = np.array(image)\n",
    "                composite = segments * (1-a) + image * a\n",
    "                for c in range(3):\n",
    "                    indexes = labels == 0\n",
    "                    composite[:,:,c][indexes] = image[:,:,c][indexes]\n",
    "                    \n",
    "                composite = np.flip(np.array(composite),2)\n",
    "                showFrame(composite.astype('uint8'))\n",
    "                display.clear_output(wait=True)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        vc.release()\n",
    "        print \"Stream stopped\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
